{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import timeit\n",
    "\n",
    "# Importing the dataset from the url\n",
    "url =  \"https://raw.githubusercontent.com/uzay00/KaVe/master/Ders3/data/Social_Network_Ads.csv\"\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15728773</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>58000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0\n",
       "5  15728773    Male   27            58000          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   19, 19000],\n",
       "       [   35, 20000],\n",
       "       [   26, 43000],\n",
       "       [   27, 57000],\n",
       "       [   19, 76000],\n",
       "       [   27, 58000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, [2, 3]].values\n",
    "y = data.iloc[:, 4].values\n",
    "\n",
    "X[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our own Logistic Regression Class\n",
    "![alt text](https://raw.githubusercontent.com/uzay00/KaVe/master/Ders3/data/myclassifier.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return(1 / (1 + np.exp(-z)))\n",
    "  \n",
    "class myClassification():\n",
    "    def __init__(self,X_train, y_train):\n",
    "        self.m, self.n = X_train.shape\n",
    "        self.n += 1 # Add one for x_0 column \n",
    "        \n",
    "        self.X_train = np.hstack((np.ones((self.m,1)), X_train))\n",
    "        self.y_train = y_train.reshape((self.m,1))\n",
    "        self.W = np.random.randn(self.n,1)\n",
    "            \n",
    "    def cost(self):\n",
    "        h = sigmoid(self.X_train.dot(self.W))\n",
    "        return np.sum(np.power(h-self.y_train,2))/ (2*self.m)\n",
    "\n",
    "    def derivative(self):\n",
    "        h = sigmoid(self.X_train.dot(self.W))\n",
    "        derivative = np.sum(self.X_train * (h-self.y_train) * h * (1-h) , axis=0)/ self.m\n",
    "        return derivative.reshape(self.W.shape)\n",
    "\n",
    "    def gradient_descent(self, alpha = 0.05, number_steps = 10000):\n",
    "        for i in range(number_steps):\n",
    "            self.W = self.W - alpha * self.derivative()\n",
    "        return self.W\n",
    "    \n",
    "    def predict(self, X_test, threshold=0.5):\n",
    "        m, n = X_test.shape\n",
    "        X_test = np.hstack((np.ones((m,1)), X_test))\n",
    "        h = sigmoid(X_test.dot(self.W)) \n",
    "        p = h >= threshold\n",
    "        return (p.astype('int'))\n",
    "\n",
    "    def fit(self):\n",
    "        self.W = self.gradient_descent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Logistic Regression on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.11048573200059764\n",
      "\t\t\t\t\t---SKlearn Logistic Regression---\n",
      "confusion_matrix:\n",
      " [[65  3]\n",
      " [ 8 24]]\n",
      "accuracy_score:  0.89\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\t\\t\\t\\t\\t---SKlearn Logistic Regression---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.4278603999991901\n",
      "\t\t\t\t---Our Own Logistic Regression with Gradient Descent---\n",
      "confusion_matrix:\n",
      " [[64  4]\n",
      " [ 6 26]]\n",
      "accuracy_score:  0.89\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "me = myClassification(X_train, y_train)\n",
    "me.fit()\n",
    "me_pred = me.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, me_pred)\n",
    "print(\"\\t\\t\\t\\t---Our Own Logistic Regression with Gradient Descent---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with ABM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return(1 / (1 + np.exp(-z)))\n",
    " \n",
    "class agent():\n",
    "    def __init__(self,ID):\n",
    "        self.ID = ID\n",
    "        self.score = 0\n",
    "        \n",
    "    def feed(self, X_part, y_part):\n",
    "        self.m, self.n = X_part.shape\n",
    "        self.n  += 1 # Add one for x_0 column \n",
    "        \n",
    "        self.X = np.hstack((np.ones((self.m,1)), X_part))\n",
    "        self.y = y_part.reshape((self.m,1))\n",
    "        self.W = np.random.randn(self.n ,1)\n",
    "        \n",
    "        self.score = self.performance()\n",
    "    \n",
    "    def performance(self, threshold = 0.5):\n",
    "        h = sigmoid(self.X.dot(self.W)) \n",
    "        p = h >= threshold\n",
    "        return 1/(1+np.sum(np.power(self.y - p.astype('int'),2)))\n",
    "    \n",
    "    def immitate(self, other, pr = 1): # immitate betters\n",
    "        if np.random.rand() < pr:\n",
    "            k =  max(int(self.n * 0.4),1)\n",
    "            row = np.random.randint(self.n,size =k)\n",
    "            self.W[row,:] = other.W[row,:]\n",
    "            self.score = self.performance()\n",
    "                  \n",
    "    def innovate(self, pr = 1):\n",
    "        if np.random.rand() < pr: # Go on your own - mutation\n",
    "            k =  max(self.n//5,1)\n",
    "            row = np.random.randint(self.n,size =k)\n",
    "            self.W[row,:] = np.random.randn(k,1)\n",
    "            self.score = self.performance()\n",
    "    \n",
    "        \n",
    "class abmClassifier():\n",
    "    def __init__(self, X, y, N = 500, time = 200000):\n",
    "        self.X, self.y, self.N, self.time = X, y, N, time\n",
    "        self.population = [agent(i) for i in range(self.N)]\n",
    "        \n",
    "    def feed(self):\n",
    "        for A in self.population:\n",
    "            A.feed(self.X, self.y) \n",
    "    \n",
    "    def social_optimisation(self):\n",
    "        self.feed()\n",
    "        for i in range(self.time):\n",
    "            iA, iB = np.random.choice(range(self.N), 2, replace=False)\n",
    "            A, B = self.population[iA], self.population[iB]\n",
    "            \n",
    "            if A.score > B.score: B.immitate(A)\n",
    "            else: A.immitate(B)\n",
    "                \n",
    "            A.innovate();B.innovate()\n",
    "            \n",
    "            \n",
    "    def best_agent(self):   \n",
    "        scores = [A.score for A in self.population]\n",
    "        ibest = scores.index(max(scores))\n",
    "        return self.population[ibest]\n",
    "        \n",
    "    def predict(self, X_test, threshold = 0.5):\n",
    "        m, n = X_test.shape\n",
    "        X_test = np.hstack((np.ones((m,1)), X_test))\n",
    "        \n",
    "        h = sigmoid(X_test.dot(self.best_agent().W)) \n",
    "        p = h >= threshold\n",
    "        return (p.astype('int'))\n",
    "    \n",
    "    def fit(self):\n",
    "        self.social_optimisation()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  36.77802290799991\n",
      "\t\t\t\t---Our Own Logistic Regression with ABM---\n",
      "confusion_matrix:\n",
      " [[63  5]\n",
      " [ 4 28]]\n",
      "accuracy_score:  0.91\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "abm = abmClassifier(X_train, y_train)\n",
    "abm.fit()\n",
    "abm_pred = abm.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, abm_pred)\n",
    "print(\"\\t\\t\\t\\t---Our Own Logistic Regression with ABM---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, abm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.48711214899958577\n",
      "\t\t\t\t---SKLearn Neural Networks---\n",
      "confusion_matrix:\n",
      " [[63  5]\n",
      " [ 5 27]]\n",
      "accuracy_score:  0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "nn=MLPClassifier(hidden_layer_sizes=(7,), max_iter=1000, alpha=0.1,\n",
    "                     solver='sgd',  random_state=21,tol=0.000000001)\n",
    "\n",
    "nn.fit(X_train,y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = nn.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\t\\t\\t\\t---SKLearn Neural Networks---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.00667131099908147\n",
      "\t\t\t\t\t---SKlearn Naive Bayes---\n",
      "confusion_matrix:\n",
      " [[50 47]\n",
      " [12 91]]\n",
      "accuracy_score:  0.705\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "url = 'https://raw.githubusercontent.com/uzay00/KaVe/master/Proje3/Restaurant_Reviews.tsv'\n",
    "dataset = pd.read_csv(url, delimiter = '\\t', quoting = 3)\n",
    "\n",
    "# Cleaning the texts\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, 1000):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "start_time = timeit.default_timer()\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\t\\t\\t\\t\\t---SKlearn Naive Bayes---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.1331212040004175\n",
      "\t\t\t\t\t---SKlearn Logistic Regression---\n",
      "confusion_matrix:\n",
      " [[68 29]\n",
      " [29 74]]\n",
      "accuracy_score:  0.71\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "start_time = timeit.default_timer()\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\t\\t\\t\\t\\t---SKlearn Logistic Regression---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  32.84267134100082\n",
      "\t\t\t\t---Our Own Logistic Regression with Gradient Descent---\n",
      "confusion_matrix:\n",
      " [[57 40]\n",
      " [45 58]]\n",
      "accuracy_score:  0.71\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "me = myClassification(X_train, y_train)\n",
    "me.fit()\n",
    "me_pred = me.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, me_pred)\n",
    "print(\"\\t\\t\\t\\t---Our Own Logistic Regression with Gradient Descent---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  135.16589753599874\n",
      "\t\t\t\t---Our Own Logistic Regression with ABM---\n",
      "confusion_matrix:\n",
      " [[51 46]\n",
      " [55 48]]\n",
      "accuracy_score:  0.495\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "abm = abmClassifier(X_train, y_train)\n",
    "abm.fit()\n",
    "abm_pred = abm.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, abm_pred)\n",
    "print(\"\\t\\t\\t\\t---Our Own Logistic Regression with ABM---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, abm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  2.3067403200002445\n",
      "\t\t\t\t---SKLearn Neural Networks---\n",
      "confusion_matrix:\n",
      " [[80 17]\n",
      " [31 72]]\n",
      "accuracy_score:  0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "nn=MLPClassifier(hidden_layer_sizes=(7,), max_iter=1000, alpha=0.1,\n",
    "                     solver='sgd',  random_state=21,tol=0.000000001)\n",
    "\n",
    "nn.fit(X_train,y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = nn.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\t\\t\\t\\t---SKLearn Neural Networks---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
