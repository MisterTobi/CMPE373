{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import timeit\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.08996555898920633\n",
      "\t\t\t\t\t---SKlearn Logistic Regression---\n",
      "confusion_matrix:\n",
      " [[50  3]\n",
      " [ 3 87]]\n",
      "accuracy_score:  0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\t\\t\\t\\t\\t---SKlearn Logistic Regression---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handmade Logistic Regression\n",
    "![alt text](https://raw.githubusercontent.com/uzay00/KaVe/master/Ders3/data/myclassifier.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return(1 / (1 + np.exp(-z)))\n",
    "  \n",
    "class myClassification():\n",
    "    def __init__(self,X_train, y_train):\n",
    "        self.m, self.n = X_train.shape\n",
    "        self.n += 1 # Add one for x_0 column \n",
    "        \n",
    "        self.X_train = np.hstack((np.ones((self.m,1)), X_train))\n",
    "        self.y_train = y_train.reshape((self.m,1))\n",
    "        self.W = np.random.randn(self.n,1)\n",
    "            \n",
    "    def cost(self):\n",
    "        h = sigmoid(self.X_train.dot(self.W))\n",
    "        return np.sum(np.power(h-self.y_train,2))/ (2*self.m)\n",
    "\n",
    "    def derivative(self):\n",
    "        h = sigmoid(self.X_train.dot(self.W))\n",
    "        derivative = np.sum(self.X_train * (h-self.y_train) * h * (1-h) , axis=0)/ self.m\n",
    "        return derivative.reshape(self.W.shape)\n",
    "\n",
    "    def gradient_descent(self, alpha = 0.05, number_steps = 10000):\n",
    "        for i in range(number_steps):\n",
    "            self.W = self.W - alpha * self.derivative()\n",
    "        return self.W\n",
    "    \n",
    "    def predict(self, X_test, threshold=0.5):\n",
    "        m, n = X_test.shape\n",
    "        X_test = np.hstack((np.ones((m,1)), X_test))\n",
    "        h = sigmoid(X_test.dot(self.W)) \n",
    "        p = h >= threshold\n",
    "        return (p.astype('int'))\n",
    "\n",
    "    def fit(self):\n",
    "        self.W = self.gradient_descent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.6886791269935202\n",
      "\t\t\t\t---Our Own Logistic Regression with Gradient Descent---\n",
      "confusion_matrix:\n",
      " [[50  3]\n",
      " [ 1 89]]\n",
      "accuracy_score:  0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "me = myClassification(X_train, y_train)\n",
    "me.fit()\n",
    "me_pred = me.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, me_pred)\n",
    "print(\"\\t\\t\\t\\t---Our Own Logistic Regression with Gradient Descent---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, me_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABM-based Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return(1 / (1 + np.exp(-z)))\n",
    " \n",
    "class agent():\n",
    "    def __init__(self,ID):\n",
    "        self.ID = ID\n",
    "        self.score = 0\n",
    "        \n",
    "    def feed(self, X_part, y_part):\n",
    "        self.m, self.n = X_part.shape\n",
    "        self.n  += 1 # Add one for x_0 column \n",
    "        \n",
    "        self.X = np.hstack((np.ones((self.m,1)), X_part))\n",
    "        self.y = y_part.reshape((self.m,1))\n",
    "        self.W = np.random.randn(self.n ,1)\n",
    "        \n",
    "        self.score = self.performance()\n",
    "    \n",
    "    def performance(self, threshold = 0.5):\n",
    "        h = sigmoid(self.X.dot(self.W)) \n",
    "        p = h >= threshold\n",
    "        return 1/(1+np.sum(np.power(self.y - p.astype('int'),2)))\n",
    "    \n",
    "    def immitate(self, other, pr = 1): # immitate betters\n",
    "        if np.random.rand() < pr:\n",
    "            k =  max(int(self.n * 0.8),1)\n",
    "            row = np.random.randint(self.n,size =k)\n",
    "            self.W[row,:] = other.W[row,:]\n",
    "            self.score = self.performance()\n",
    "                  \n",
    "    def innovate(self, pr = 1):\n",
    "        if np.random.rand() < pr: # Go on your own - mutation\n",
    "            k =  max(self.n//10,1)\n",
    "            row = np.random.randint(self.n,size =k)\n",
    "            self.W[row,:] = np.random.randn(k,1)\n",
    "            self.score = self.performance()\n",
    "    \n",
    "        \n",
    "class abmClassifier():\n",
    "    def __init__(self, X, y, N = 100, time = 1000):\n",
    "        self.X, self.y, self.N, self.time = X, y, N, time\n",
    "        self.population = [agent(i) for i in range(self.N)]\n",
    "        \n",
    "    def feed(self):\n",
    "        for A in self.population:\n",
    "            A.feed(self.X, self.y) \n",
    "    \n",
    "    def social_optimisation(self):\n",
    "        self.feed()\n",
    "        for i in range(self.time):\n",
    "            iA, iB = np.random.choice(range(self.N), 2, replace=False)\n",
    "            A, B = self.population[iA], self.population[iB]\n",
    "            \n",
    "            if A.score > B.score: B.immitate(A)\n",
    "            else: A.immitate(B)\n",
    "                \n",
    "            A.innovate();B.innovate()\n",
    "            \n",
    "            \n",
    "    def best_agent(self):   \n",
    "        scores = [A.score for A in self.population]\n",
    "        ibest = scores.index(max(scores))\n",
    "        return self.population[ibest]\n",
    "        \n",
    "    def predict(self, X_test, threshold = 0.5):\n",
    "        m, n = X_test.shape\n",
    "        X_test = np.hstack((np.ones((m,1)), X_test))\n",
    "        \n",
    "        h = sigmoid(X_test.dot(self.best_agent().W)) \n",
    "        p = h >= threshold\n",
    "        return (p.astype('int'))\n",
    "    \n",
    "    def fit(self):\n",
    "        self.social_optimisation()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.1753951399878133\n",
      "\t\t\t\t---Our Own Logistic Regression with ABM---\n",
      "confusion_matrix:\n",
      " [[50  3]\n",
      " [ 3 87]]\n",
      "accuracy_score:  0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "abm = abmClassifier(X_train, y_train)\n",
    "abm.fit()\n",
    "abm_pred = abm.predict(X_test)\n",
    "\n",
    "print(\"Time: \", timeit.default_timer() - start_time)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, abm_pred)\n",
    "print(\"\\t\\t\\t\\t---Our Own Logistic Regression with ABM---\")\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, abm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
